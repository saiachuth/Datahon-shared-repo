{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cd23b81a-ba37-4469-9ab8-e1d70a1dfbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "02b061d3-c580-46c5-972f-eefc50b93b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>severityavg_severity</th>\n",
       "      <th>severitymax_severity</th>\n",
       "      <th>severitynum_barriers</th>\n",
       "      <th>lengthfirst</th>\n",
       "      <th>CurbRamp_count</th>\n",
       "      <th>NoCurbRamp_count</th>\n",
       "      <th>NoSidewalk_count</th>\n",
       "      <th>Obstacle_count</th>\n",
       "      <th>...</th>\n",
       "      <th>NoCurbRamp_max</th>\n",
       "      <th>NoSidewalk_max</th>\n",
       "      <th>Obstacle_max</th>\n",
       "      <th>Occlusion_max</th>\n",
       "      <th>Other_max</th>\n",
       "      <th>SurfaceProblem_max</th>\n",
       "      <th>u_lat</th>\n",
       "      <th>u_lon</th>\n",
       "      <th>v_lat</th>\n",
       "      <th>v_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>317.313855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.662018</td>\n",
       "      <td>-122.322863</td>\n",
       "      <td>47.664871</td>\n",
       "      <td>-122.322864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.772566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.648425</td>\n",
       "      <td>-122.342633</td>\n",
       "      <td>47.648600</td>\n",
       "      <td>-122.342604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.534974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646925</td>\n",
       "      <td>-122.336374</td>\n",
       "      <td>47.646803</td>\n",
       "      <td>-122.336373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.156787</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646921</td>\n",
       "      <td>-122.334031</td>\n",
       "      <td>47.647067</td>\n",
       "      <td>-122.334030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.729261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.665809</td>\n",
       "      <td>-122.301937</td>\n",
       "      <td>47.665880</td>\n",
       "      <td>-122.302052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  key  severityavg_severity  severitymax_severity  \\\n",
       "0           0  0.0                   1.0                   1.0   \n",
       "1           1  0.0                   1.0                   1.0   \n",
       "2           2  0.0                   2.0                   3.0   \n",
       "3           3  0.0                   1.0                   1.0   \n",
       "4           4  0.0                   3.0                   3.0   \n",
       "\n",
       "   severitynum_barriers  lengthfirst  CurbRamp_count  NoCurbRamp_count  \\\n",
       "0                     1   317.313855               1                 0   \n",
       "1                     2    19.772566               2                 0   \n",
       "2                     2    13.534974               2                 0   \n",
       "3                     2    16.156787               2                 0   \n",
       "4                     1    11.729261               1                 0   \n",
       "\n",
       "   NoSidewalk_count  Obstacle_count  ...  NoCurbRamp_max  NoSidewalk_max  \\\n",
       "0                 0               0  ...             0.0             0.0   \n",
       "1                 0               0  ...             0.0             0.0   \n",
       "2                 0               0  ...             0.0             0.0   \n",
       "3                 0               0  ...             0.0             0.0   \n",
       "4                 0               0  ...             0.0             0.0   \n",
       "\n",
       "   Obstacle_max  Occlusion_max  Other_max  SurfaceProblem_max      u_lat  \\\n",
       "0           0.0            0.0        0.0                 0.0  47.662018   \n",
       "1           0.0            0.0        0.0                 0.0  47.648425   \n",
       "2           0.0            0.0        0.0                 0.0  47.646925   \n",
       "3           0.0            0.0        0.0                 0.0  47.646921   \n",
       "4           0.0            0.0        0.0                 0.0  47.665809   \n",
       "\n",
       "        u_lon      v_lat       v_lon  \n",
       "0 -122.322863  47.664871 -122.322864  \n",
       "1 -122.342633  47.648600 -122.342604  \n",
       "2 -122.336374  47.646803 -122.336373  \n",
       "3 -122.334031  47.647067 -122.334030  \n",
       "4 -122.301937  47.665880 -122.302052  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"gnn_input.csv\")\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1d842ade-2437-4a54-a17a-c7021eb77bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'key', 'severityavg_severity', 'severitymax_severity',\n",
       "       'severitynum_barriers', 'lengthfirst', 'CurbRamp_count',\n",
       "       'NoCurbRamp_count', 'NoSidewalk_count', 'Obstacle_count',\n",
       "       'Occlusion_count', 'Other_count', 'SurfaceProblem_count',\n",
       "       'CurbRamp_avg', 'NoCurbRamp_avg', 'NoSidewalk_avg', 'Obstacle_avg',\n",
       "       'Occlusion_avg', 'Other_avg', 'SurfaceProblem_avg', 'CurbRamp_max',\n",
       "       'NoCurbRamp_max', 'NoSidewalk_max', 'Obstacle_max', 'Occlusion_max',\n",
       "       'Other_max', 'SurfaceProblem_max', 'u_lat', 'u_lon', 'v_lat', 'v_lon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(\"gnn_input.csv\")\n",
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fc1db889-587a-4fb3-bec7-83f6f2edcf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Seattle graph\n",
      "Nodes: 109164\n",
      "Edges: 149957\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "# Download Seattle walk network\n",
    "G_full = ox.graph_from_place(\n",
    "    \"Seattle, Washington, USA\",\n",
    "    network_type=\"walk\"\n",
    ")\n",
    "G_full = nx.Graph(G_full)\n",
    "\n",
    "print(\"Base Seattle graph\")\n",
    "print(\"Nodes:\", G_full.number_of_nodes())\n",
    "print(\"Edges:\", G_full.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "befdd47c-2b10-476a-a1e1-344fc39af676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a58824a1-2183-47d8-a272-af28580a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mobility GNN score - edge based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4812d7b0-0b79-4998-b4be-f89ea10de1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x.copy()  # <-- use your existing DataFrame here\n",
    "\n",
    "def key(lat, lon):\n",
    "    return (round(lat, 6), round(lon, 6))\n",
    "\n",
    "# Map: (u_coord, v_coord) -> row with barrier features\n",
    "edge_features = {}\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    u = key(r.u_lat, r.u_lon)\n",
    "    v = key(r.v_lat, r.v_lon)\n",
    "    edge_features[(u, v)] = r\n",
    "    edge_features[(v, u)] = r  # undirected\n",
    "\n",
    "# Attach features to each NetworkX edge\n",
    "for u, v in G_full.edges():\n",
    "    # Node coordinates from OSMnx\n",
    "    u_coord = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_coord = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "\n",
    "    data_row = edge_features.get((u_coord, v_coord), None)\n",
    "\n",
    "    if data_row is None:\n",
    "        G_full[u][v][\"features\"] = {\n",
    "            \"NoCurbRamp\": 0.0,\n",
    "            \"NoSidewalk\": 0.0,\n",
    "            \"Obstacle\": 0.0,\n",
    "            \"CurbRamp\": 1.0,          # default: safe\n",
    "            \"SurfaceProblem\": 0.0,\n",
    "            \"Occlusion\": 0.0\n",
    "        }\n",
    "    else:\n",
    "        G_full[u][v][\"features\"] = {\n",
    "            \"NoCurbRamp\": float(data_row[\"NoCurbRamp_count\"]),\n",
    "            \"NoSidewalk\": float(data_row[\"NoSidewalk_count\"]),\n",
    "            \"Obstacle\": float(data_row[\"Obstacle_count\"]),\n",
    "            \"CurbRamp\": float(data_row[\"CurbRamp_count\"]),\n",
    "            \"SurfaceProblem\": float(data_row[\"SurfaceProblem_count\"]),\n",
    "            \"Occlusion\": float(data_row[\"Occlusion_count\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8f4676c8-8e71-4800-ba4b-d2073f6d7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobility_risk(f):\n",
    "    return (\n",
    "        5.0 * f[\"NoCurbRamp\"] +\n",
    "        4.0 * f[\"NoSidewalk\"] +\n",
    "        3.0 * f[\"Obstacle\"] +\n",
    "        2.0 * max(0.0, 1.0 - f[\"CurbRamp\"]) +   # no curb ramp is bad\n",
    "        1.5 * f[\"SurfaceProblem\"] +\n",
    "        1.0 * f[\"Occlusion\"]\n",
    "    )\n",
    "\n",
    "# Precompute target risk per edge (for now using analytic formula)\n",
    "edge_list = list(G_full.edges())\n",
    "y_vals = []\n",
    "x_feats = []\n",
    "\n",
    "for (u, v) in edge_list:\n",
    "    f = G_full[u][v][\"features\"]\n",
    "    x_feats.append([\n",
    "        f[\"NoCurbRamp\"],\n",
    "        f[\"NoSidewalk\"],\n",
    "        f[\"Obstacle\"],\n",
    "        f[\"CurbRamp\"],\n",
    "        f[\"SurfaceProblem\"],\n",
    "        f[\"Occlusion\"]\n",
    "    ])\n",
    "    y_vals.append(mobility_risk(f))\n",
    "\n",
    "x = torch.tensor(x_feats, dtype=torch.float)       # [num_edges, 6]\n",
    "y = torch.tensor(y_vals, dtype=torch.float)        # [num_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a08a88d1-8733-4e86-aa77-f9f54a753c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line graph nodes (edges): 149957\n",
      "Line graph edges: 647696\n"
     ]
    }
   ],
   "source": [
    "# 1) Build canonical edge_list from the graph\n",
    "def canon_edge(u, v):\n",
    "    # Assume undirected: represent edges as sorted tuples\n",
    "    return (u, v) if u <= v else (v, u)\n",
    "\n",
    "edge_list = [canon_edge(u, v) for (u, v) in G_full.edges()]  # canonical\n",
    "num_edges = len(edge_list)\n",
    "\n",
    "# 2) Build x, y using canonical edge_list\n",
    "x_feats = []\n",
    "y_vals = []\n",
    "\n",
    "for (u_c, v_c) in edge_list:\n",
    "    f = G_full[u_c][v_c][\"features\"]\n",
    "    x_feats.append([\n",
    "        f[\"NoCurbRamp\"],\n",
    "        f[\"NoSidewalk\"],\n",
    "        f[\"Obstacle\"],\n",
    "        f[\"CurbRamp\"],\n",
    "        f[\"SurfaceProblem\"],\n",
    "        f[\"Occlusion\"],\n",
    "    ])\n",
    "    y_vals.append(mobility_risk(f))\n",
    "\n",
    "x = torch.tensor(x_feats, dtype=torch.float)\n",
    "y = torch.tensor(y_vals, dtype=torch.float)\n",
    "\n",
    "# 3) Map canonical edge -> index\n",
    "e2idx = {e: i for i, e in enumerate(edge_list)}\n",
    "\n",
    "# 4) Build line-graph edge_index using the SAME canonicalization\n",
    "edge_index_list = []\n",
    "\n",
    "for w in G_full.nodes():\n",
    "    # incident edges as canonical pairs\n",
    "    incident_raw = list(G_full.edges(w))\n",
    "    incident = [canon_edge(u, v) for (u, v) in incident_raw]\n",
    "\n",
    "    # Fully connect them\n",
    "    for i in range(len(incident)):\n",
    "        for j in range(i + 1, len(incident)):\n",
    "            ei = e2idx[incident[i]]\n",
    "            ej = e2idx[incident[j]]\n",
    "            edge_index_list.append([ei, ej])\n",
    "            edge_index_list.append([ej, ei])\n",
    "\n",
    "if len(edge_index_list) == 0:\n",
    "    raise ValueError(\"Line graph has no edges; check your input graph.\")\n",
    "\n",
    "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "print(\"Line graph nodes (edges):\", data.num_nodes)\n",
    "print(\"Line graph edges:\", data.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "687d9a16-404f-48ef-8eab-2d6a2f0ba855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4238fb06-e090-446e-8068-2531d9b8cc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[149957, 6], edge_index=[2, 647696], y=[149957])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "70df00ad-af8e-4af4-a0d7-cfcb14b0bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss 10.0140\n",
      "Epoch  20 | Loss 0.4130\n",
      "Epoch  40 | Loss 0.0900\n",
      "Epoch  60 | Loss 0.0324\n",
      "Epoch  80 | Loss 0.0149\n",
      "Epoch 100 | Loss 0.0107\n",
      "Epoch 120 | Loss 0.0086\n",
      "Epoch 140 | Loss 0.0071\n",
      "Epoch 160 | Loss 0.0061\n",
      "Epoch 180 | Loss 0.0053\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "#############################################\n",
    "# 1. Edge-based GNN model and training\n",
    "#############################################\n",
    "\n",
    "class MobilityEdgeGNN(nn.Module):\n",
    "    def __init__(self, in_channels=6, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        self.gnn = GraphSAGE(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            num_layers=2\n",
    "        )\n",
    "        self.head = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gnn(x, edge_index)      # [num_edges, hidden]\n",
    "        out = self.head(h).squeeze(-1)   # [num_edges]\n",
    "        return out\n",
    "\n",
    "model = MobilityEdgeGNN(in_channels=6, hidden_channels=32)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    pred = model(data.x, data.edge_index)     # [num_edges]\n",
    "    loss = ((pred - data.y) ** 2).mean()\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b731c787-2b07-401c-b206-5d848b065de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 predicted risks: [-6.6369027e-04  1.9801930e-02  1.9801930e-02 -6.6369027e-04\n",
      " -6.6371262e-04  5.0970428e-02 -6.6371262e-04 -1.1709638e-02\n",
      " -6.6371262e-04 -6.6371262e-04 -6.6371262e-04 -1.4102075e-01\n",
      " -6.6371262e-04 -2.9860772e-02 -6.6371262e-04 -6.6371262e-04\n",
      " -6.4177811e-03  3.0123644e-02  1.4648864e-01  7.0026240e+00]\n",
      "Unique risk values (rounded): [ -1.2456  -1.1694  -1.0706 ... 102.1461 106.0935 110.4468]\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2. Attach learned risk to original edges\n",
    "#############################################\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    risk_pred = model(data.x, data.edge_index).cpu().numpy()  # [num_edges]\n",
    "\n",
    "print(\"First 20 predicted risks:\", risk_pred[:20])\n",
    "print(\"Unique risk values (rounded):\", np.unique(np.round(risk_pred, 4)))\n",
    "\n",
    "# edge_list must be in canonical form: (min(u,v), max(u,v))\n",
    "for i, (u_c, v_c) in enumerate(edge_list):\n",
    "    G_full[u_c][v_c][\"risk\"] = float(risk_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1c48eab0-f875-485b-bd16-f0e1383399f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True risk[0:20]: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7.]\n",
      "Pred risk[0:20]: [-6.6369027e-04  1.9801930e-02  1.9801930e-02 -6.6369027e-04\n",
      " -6.6371262e-04  5.0970428e-02 -6.6371262e-04 -1.1709638e-02\n",
      " -6.6371262e-04 -6.6371262e-04 -6.6371262e-04 -1.4102075e-01\n",
      " -6.6371262e-04 -2.9860772e-02 -6.6371262e-04 -6.6371262e-04\n",
      " -6.4177811e-03  3.0123644e-02  1.4648864e-01  7.0026240e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"True risk[0:20]:\", data.y[:20].numpy())\n",
    "print(\"Pred risk[0:20]:\", risk_pred[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0e8e8845-5898-47a3-b5a9-30f9597a2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted risks (rounded to 3 decimals): [ -1.246  -1.169  -1.071 ... 102.146 106.094 110.447]\n",
      "Min pred risk: -1.2456201\n",
      "Max pred risk: 110.44684\n",
      "Mean pred risk: 0.8870475\n",
      "Std pred risk: 3.0630903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Unique values (can be a lot, so maybe round first)\n",
    "unique_vals = np.unique(np.round(risk_pred, 3))\n",
    "print(\"Unique predicted risks (rounded to 3 decimals):\", unique_vals)\n",
    "\n",
    "# Basic stats / range\n",
    "print(\"Min pred risk:\", risk_pred.min())\n",
    "print(\"Max pred risk:\", risk_pred.max())\n",
    "print(\"Mean pred risk:\", risk_pred.mean())\n",
    "print(\"Std pred risk:\", risk_pred.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ec30568f-3bb4-41ee-a974-30e578731273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th percentile (Q1): -0.001\n",
      "75th percentile (Q3): 0.018\n",
      "Min: -1.246\n",
      "Median (50th): -0.001\n",
      "Max: 110.447\n",
      "IQR (p75 - p25): 0.019\n",
      "\n",
      "Quartile breakdown:\n",
      "Q1-Q3 (25th-75th): 80075 edges (53.4%)\n",
      "Below Q1 (< -0.0): 32397 edges (21.6%)\n",
      "Above Q3 (> 0.0): 37485 edges (25.0%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate 25th and 75th percentiles of risk_pred\n",
    "p25 = np.percentile(risk_pred, 25)\n",
    "p75 = np.percentile(risk_pred, 75)\n",
    "\n",
    "print(f\"25th percentile (Q1): {p25:.3f}\")\n",
    "print(f\"75th percentile (Q3): {p75:.3f}\")\n",
    "\n",
    "# Also show basic stats\n",
    "print(f\"Min: {risk_pred.min():.3f}\")\n",
    "print(f\"Median (50th): {np.percentile(risk_pred, 50):.3f}\")\n",
    "print(f\"Max: {risk_pred.max():.3f}\")\n",
    "\n",
    "# Interquartile range (IQR)\n",
    "iqr = p75 - p25\n",
    "print(f\"IQR (p75 - p25): {iqr:.3f}\")\n",
    "\n",
    "# Count of edges in each quartile\n",
    "n_total = len(risk_pred)\n",
    "print(f\"\\nQuartile breakdown:\")\n",
    "print(f\"Q1-Q3 (25th-75th): {np.sum((risk_pred >= p25) & (risk_pred <= p75))} edges ({100*(np.sum((risk_pred >= p25) & (risk_pred <= p75))/n_total):.1f}%)\")\n",
    "print(f\"Below Q1 (< {p25:.1f}): {np.sum(risk_pred < p25)} edges ({100*(np.sum(risk_pred < p25)/n_total):.1f}%)\")\n",
    "print(f\"Above Q3 (> {p75:.1f}): {np.sum(risk_pred > p75)} edges ({100*(np.sum(risk_pred > p75)/n_total):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "567f2039-da96-439b-a764-8074defd93ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling anchors:\n",
      "  Min: -1.246 -> 0\n",
      "  p95: 9.850 -> 7\n",
      "  Max: 110.447 -> 10\n",
      "\n",
      "After rescaling:\n",
      "  Range: [0.00, 10.00]\n",
      "  Fraction >= 7: 2.0%\n",
      "  p25: 0.79\n",
      "  p75: 0.80\n",
      "  p95: 5.19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For TOP 5% data >= 7, use the 95th percentile as cutoff\n",
    "p95 = np.percentile(risk_pred, 98)  # 95th percentile -> maps to 7 (top 5%)\n",
    "r_min, r_max = risk_pred.min(), risk_pred.max()\n",
    "\n",
    "print(f\"Rescaling anchors:\")\n",
    "print(f\"  Min: {r_min:.3f} -> 0\")\n",
    "print(f\"  p95: {p95:.3f} -> 7\") \n",
    "print(f\"  Max: {r_max:.3f} -> 10\")\n",
    "\n",
    "def rescale_top5pct(risk_val):\n",
    "    \"\"\"Rescale so TOP 5% of data >= 7, range [0,10]\"\"\"\n",
    "    if risk_val <= p95:\n",
    "        # [r_min, p95] -> [0, 7]  (95% of data)\n",
    "        if p95 == r_min:\n",
    "            return 0.0\n",
    "        return 7.0 * (risk_val - r_min) / (p95 - r_min)\n",
    "    else:\n",
    "        # [p95, r_max] -> [7, 10] (top 5%)\n",
    "        if r_max == p95:\n",
    "            return 10.0\n",
    "        return 7.0 + 3.0 * (risk_val - p95) / (r_max - p95)\n",
    "\n",
    "# Apply to all predictions\n",
    "risk_normalized = np.array([rescale_top5pct(val) for val in risk_pred])\n",
    "risk_normalized = np.clip(risk_normalized, 0, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Verify\n",
    "print(f\"\\nAfter rescaling:\")\n",
    "print(f\"  Range: [{risk_normalized.min():.2f}, {risk_normalized.max():.2f}]\")\n",
    "print(f\"  Fraction >= 7: {np.mean(risk_normalized >= 7):.1%}\")  # ~5%\n",
    "print(f\"  p25: {np.percentile(risk_normalized, 25):.2f}\")\n",
    "print(f\"  p75: {np.percentile(risk_normalized, 75):.2f}\")\n",
    "print(f\"  p95: {np.percentile(risk_normalized, 95):.2f}\")\n",
    "\n",
    "# Attach normalized risk to graph\n",
    "for i, (u_c, v_c) in enumerate(edge_list):\n",
    "    G_full[u_c][v_c][\"risk_norm\"] = float(risk_normalized[i])\n",
    "\n",
    "# Update wheelchair_cost with normalized risk (0-10 scale)\n",
    "alpha = 1.0  # distance weight\n",
    "beta = 2.0   # risk weight (tune for 0-10 scale)\n",
    "\n",
    "for u, v, d in G_full.edges(data=True):\n",
    "    length = d.get(\"length\", 1.0)\n",
    "    risk_norm = d.get(\"risk_norm\", 0.0)\n",
    "    d[\"wheelchair_cost\"] = alpha * length + beta * risk_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "585a42e5-a54d-4e5e-827d-8335031d35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame updated with 'pred' column.\n",
      "       u_lat       u_lon      v_lat       v_lon  pred\n",
      "0  47.662018 -122.322863  47.664871 -122.322864   0.0\n",
      "1  47.648425 -122.342633  47.648600 -122.342604   0.0\n",
      "2  47.646925 -122.336374  47.646803 -122.336373   0.0\n",
      "3  47.646921 -122.334031  47.647067 -122.334030   0.0\n",
      "4  47.665809 -122.301937  47.665880 -122.302052   0.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a lookup dictionary: (canonical_u, canonical_v) -> risk_norm\n",
    "# We use the canonicalized keys to ensure the undirected match works\n",
    "risk_lookup = {}\n",
    "for i, (u_c, v_c) in enumerate(edge_list):\n",
    "    risk_lookup[(u_c, v_c)] = float(risk_normalized[i])\n",
    "\n",
    "# 2. Map the risk back to the original DataFrame\n",
    "def get_risk_for_row(row):\n",
    "    # Convert row coordinates to the canonical key format used in the GNN\n",
    "    u_coord = key(row['u_lat'], row['u_lon'])\n",
    "    v_coord = key(row['v_lat'], row['v_lon'])\n",
    "    \n",
    "    # Canonicalize the pair (min, max) to match the risk_lookup keys\n",
    "    canon_key = (u_coord, v_coord) if u_coord <= v_coord else (v_coord, u_coord)\n",
    "    \n",
    "    # Return the normalized risk, default to 0.0 if not found\n",
    "    return risk_lookup.get(canon_key, 0.0)\n",
    "\n",
    "# 3. Add the column to your input data\n",
    "df['pred'] = df.apply(get_risk_for_row, axis=1)\n",
    "\n",
    "print(\"DataFrame updated with 'pred' column.\")\n",
    "print(df[['u_lat', 'u_lon', 'v_lat', 'v_lon', 'pred']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b08b396a-5e49-4d5a-8647-dd3096c910a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Pred Min: 0.0\n",
      "Raw Pred Max: 10.0\n",
      "Raw Pred Mean: 1.2783087\n"
     ]
    }
   ],
   "source": [
    "# Check if the raw model output has variety\n",
    "print(\"Raw Pred Min:\", risk_normalized.min())\n",
    "print(\"Raw Pred Max:\", risk_normalized.max())\n",
    "print(\"Raw Pred Mean:\", risk_normalized.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9986afaa-d29e-4a98-9066-3138ecacd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mobility GNN score - edge based v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6c5ba842-9453-46d1-836d-e49c6f6363ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>severityavg_severity</th>\n",
       "      <th>severitymax_severity</th>\n",
       "      <th>severitynum_barriers</th>\n",
       "      <th>lengthfirst</th>\n",
       "      <th>CurbRamp_count</th>\n",
       "      <th>NoCurbRamp_count</th>\n",
       "      <th>NoSidewalk_count</th>\n",
       "      <th>Obstacle_count</th>\n",
       "      <th>...</th>\n",
       "      <th>NoCurbRamp_max</th>\n",
       "      <th>NoSidewalk_max</th>\n",
       "      <th>Obstacle_max</th>\n",
       "      <th>Occlusion_max</th>\n",
       "      <th>Other_max</th>\n",
       "      <th>SurfaceProblem_max</th>\n",
       "      <th>u_lat</th>\n",
       "      <th>u_lon</th>\n",
       "      <th>v_lat</th>\n",
       "      <th>v_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>317.313855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.662018</td>\n",
       "      <td>-122.322863</td>\n",
       "      <td>47.664871</td>\n",
       "      <td>-122.322864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.772566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.648425</td>\n",
       "      <td>-122.342633</td>\n",
       "      <td>47.648600</td>\n",
       "      <td>-122.342604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.534974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646925</td>\n",
       "      <td>-122.336374</td>\n",
       "      <td>47.646803</td>\n",
       "      <td>-122.336373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.156787</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646921</td>\n",
       "      <td>-122.334031</td>\n",
       "      <td>47.647067</td>\n",
       "      <td>-122.334030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.729261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.665809</td>\n",
       "      <td>-122.301937</td>\n",
       "      <td>47.665880</td>\n",
       "      <td>-122.302052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  key  severityavg_severity  severitymax_severity  \\\n",
       "0           0  0.0                   1.0                   1.0   \n",
       "1           1  0.0                   1.0                   1.0   \n",
       "2           2  0.0                   2.0                   3.0   \n",
       "3           3  0.0                   1.0                   1.0   \n",
       "4           4  0.0                   3.0                   3.0   \n",
       "\n",
       "   severitynum_barriers  lengthfirst  CurbRamp_count  NoCurbRamp_count  \\\n",
       "0                     1   317.313855               1                 0   \n",
       "1                     2    19.772566               2                 0   \n",
       "2                     2    13.534974               2                 0   \n",
       "3                     2    16.156787               2                 0   \n",
       "4                     1    11.729261               1                 0   \n",
       "\n",
       "   NoSidewalk_count  Obstacle_count  ...  NoCurbRamp_max  NoSidewalk_max  \\\n",
       "0                 0               0  ...             0.0             0.0   \n",
       "1                 0               0  ...             0.0             0.0   \n",
       "2                 0               0  ...             0.0             0.0   \n",
       "3                 0               0  ...             0.0             0.0   \n",
       "4                 0               0  ...             0.0             0.0   \n",
       "\n",
       "   Obstacle_max  Occlusion_max  Other_max  SurfaceProblem_max      u_lat  \\\n",
       "0           0.0            0.0        0.0                 0.0  47.662018   \n",
       "1           0.0            0.0        0.0                 0.0  47.648425   \n",
       "2           0.0            0.0        0.0                 0.0  47.646925   \n",
       "3           0.0            0.0        0.0                 0.0  47.646921   \n",
       "4           0.0            0.0        0.0                 0.0  47.665809   \n",
       "\n",
       "        u_lon      v_lat       v_lon  \n",
       "0 -122.322863  47.664871 -122.322864  \n",
       "1 -122.342633  47.648600 -122.342604  \n",
       "2 -122.336374  47.646803 -122.336373  \n",
       "3 -122.334031  47.647067 -122.334030  \n",
       "4 -122.301937  47.665880 -122.302052  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"gnn_input.csv\")\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c01e3-072f-49f1-bf27-9dc9d6113997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b81e536c-3d4c-4e77-8055-ade8a3cca217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "Epoch 0 | Loss 11.3818\n",
      "Epoch 50 | Loss 0.0541\n",
      "Epoch 100 | Loss 0.0105\n",
      "Epoch 150 | Loss 0.0063\n",
      "Epoch 200 | Loss 0.0048\n",
      "4\n",
      "5\n",
      "\n",
      "Final Results:\n",
      "Rows with non-zero predictions: 45589 out of 47617\n",
      "           u_lat       u_lon       pred\n",
      "795    47.557401 -122.332420  10.000000\n",
      "791    47.559834 -122.332438  10.000000\n",
      "39170  47.690536 -122.399722   9.848738\n",
      "147    47.694085 -122.400649   9.848738\n",
      "2158   47.563147 -122.336741   9.731726\n",
      "1231   47.560286 -122.336764   9.731726\n",
      "2740   47.724962 -122.323431   9.660789\n",
      "2738   47.733970 -122.322282   9.660789\n",
      "15105  47.697939 -122.375454   9.603247\n",
      "13221  47.701211 -122.375440   9.603247\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP GRAPH & DATA\n",
    "G_full = ox.graph_from_place(\"Seattle, Washington, USA\", network_type=\"walk\")\n",
    "G_full = nx.Graph(G_full)\n",
    "\n",
    "df = x.copy()\n",
    "\n",
    "print(\"1\")\n",
    "\n",
    "def key(lat, lon):\n",
    "    return (round(float(lat), 6), round(float(lon), 6))\n",
    "\n",
    "# Map coordinates to the rows in the input dataframe\n",
    "edge_features = {}\n",
    "for _, r in df.iterrows():\n",
    "    u = key(r.u_lat, r.u_lon)\n",
    "    v = key(r.v_lat, r.v_lon)\n",
    "    edge_features[(u, v)] = r\n",
    "    edge_features[(v, u)] = r \n",
    "\n",
    "# Attach features to NetworkX\n",
    "for u, v in G_full.edges():\n",
    "    u_coord = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_coord = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    data_row = edge_features.get((u_coord, v_coord))\n",
    "\n",
    "    if data_row is None:\n",
    "        G_full[u][v][\"features\"] = {\n",
    "            \"NoCurbRamp\": 0.0, \"NoSidewalk\": 0.0, \"Obstacle\": 0.0,\n",
    "            \"CurbRamp\": 1.0, \"SurfaceProblem\": 0.0, \"Occlusion\": 0.0\n",
    "        }\n",
    "    else:\n",
    "        G_full[u][v][\"features\"] = {\n",
    "            \"NoCurbRamp\": float(data_row[\"NoCurbRamp_count\"]),\n",
    "            \"NoSidewalk\": float(data_row[\"NoSidewalk_count\"]),\n",
    "            \"Obstacle\": float(data_row[\"Obstacle_count\"]),\n",
    "            \"CurbRamp\": float(data_row[\"CurbRamp_count\"]),\n",
    "            \"SurfaceProblem\": float(data_row[\"SurfaceProblem_count\"]),\n",
    "            \"Occlusion\": float(data_row[\"Occlusion_count\"])\n",
    "        }\n",
    "\n",
    "def mobility_risk(f):\n",
    "    return (5.0 * f[\"NoCurbRamp\"] + 4.0 * f[\"NoSidewalk\"] + 3.0 * f[\"Obstacle\"] +\n",
    "            2.0 * max(0.0, 1.0 - f[\"CurbRamp\"]) + 1.5 * f[\"SurfaceProblem\"] + 1.0 * f[\"Occlusion\"])\n",
    "\n",
    "# 2. PREPARE GNN DATA\n",
    "def canon_edge(u, v):\n",
    "    # Get coordinates of the nodes for canonicalization\n",
    "    u_c = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_c = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    return (u_c, v_c) if u_c <= v_c else (v_c, u_c)\n",
    "\n",
    "# We define edge_list based on canonical coordinate pairs\n",
    "edge_list_coords = [canon_edge(u, v) for (u, v) in G_full.edges()]\n",
    "x_feats, y_vals = [], []\n",
    "\n",
    "print(\"2\")\n",
    "\n",
    "for (u, v) in G_full.edges():\n",
    "    f = G_full[u][v][\"features\"]\n",
    "    x_feats.append([f[\"NoCurbRamp\"], f[\"NoSidewalk\"], f[\"Obstacle\"], f[\"CurbRamp\"], f[\"SurfaceProblem\"], f[\"Occlusion\"]])\n",
    "    y_vals.append(mobility_risk(f))\n",
    "\n",
    "x_tensor = torch.tensor(x_feats, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_vals, dtype=torch.float)\n",
    "\n",
    "# Line Graph Edge Index\n",
    "e2idx = {e: i for i, e in enumerate(edge_list_coords)}\n",
    "edge_index_list = []\n",
    "for w in G_full.nodes():\n",
    "    incident = [canon_edge(u, v) for (u, v) in G_full.edges(w)]\n",
    "    for i in range(len(incident)):\n",
    "        for j in range(i + 1, len(incident)):\n",
    "            ei, ej = e2idx[incident[i]], e2idx[incident[j]]\n",
    "            edge_index_list.extend([[ei, ej], [ej, ei]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "print(\"3\")\n",
    "\n",
    "# 3. TRAIN MODEL\n",
    "class MobilityEdgeGNN(nn.Module):\n",
    "    def __init__(self, in_channels=6, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        self.gnn = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=2)\n",
    "        self.head = nn.Linear(hidden_channels, 1)\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.head(self.gnn(x, edge_index)).squeeze(-1)\n",
    "\n",
    "model = MobilityEdgeGNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(201):\n",
    "    model.train()\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = ((pred - data.y) ** 2).mean()\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "    if epoch % 50 == 0: print(f\"Epoch {epoch} | Loss {loss.item():.4f}\")\n",
    "\n",
    "# 4. RESCALE PREDICTIONS\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    risk_pred = model(data.x, data.edge_index).cpu().numpy()\n",
    "\n",
    "print(\"4\")\n",
    "\n",
    "p95 = np.percentile(risk_pred, 98)\n",
    "r_min, r_max = risk_pred.min(), risk_pred.max()\n",
    "\n",
    "def rescale_top5pct(risk_val):\n",
    "    if risk_val <= p95:\n",
    "        return 7.0 * (risk_val - r_min) / (p95 - r_min) if p95 > r_min else 0.0\n",
    "    return 7.0 + 3.0 * (risk_val - p95) / (r_max - p95) if r_max > p95 else 10.0\n",
    "\n",
    "risk_normalized = np.clip([rescale_top5pct(v) for v in risk_pred], 0, 10)\n",
    "\n",
    "# 5. SYNC BACK TO DATAFRAME (The Correction)\n",
    "# Create a dictionary mapping coordinate pairs to the prediction\n",
    "risk_lookup = {edge_list_coords[i]: float(risk_normalized[i]) for i in range(len(edge_list_coords))}\n",
    "\n",
    "print(\"5\")\n",
    "\n",
    "def get_risk_for_row(row):\n",
    "    u_c = key(row['u_lat'], row['u_lon'])\n",
    "    v_c = key(row['v_lat'], row['v_lon'])\n",
    "    canon_key = (u_c, v_c) if u_c <= v_c else (v_c, u_c)\n",
    "    return risk_lookup.get(canon_key, 0.0)\n",
    "\n",
    "df['pred'] = df.apply(get_risk_for_row, axis=1)\n",
    "\n",
    "# VERIFICATION\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Rows with non-zero predictions: {(df['pred'] > 0).sum()} out of {len(df)}\")\n",
    "print(df[['u_lat', 'u_lon', 'pred']].sort_values(by='pred', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5d6decd2-01de-4230-9949-4a5ca7f1caf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>severityavg_severity</th>\n",
       "      <th>severitymax_severity</th>\n",
       "      <th>severitynum_barriers</th>\n",
       "      <th>lengthfirst</th>\n",
       "      <th>CurbRamp_count</th>\n",
       "      <th>NoCurbRamp_count</th>\n",
       "      <th>NoSidewalk_count</th>\n",
       "      <th>Obstacle_count</th>\n",
       "      <th>...</th>\n",
       "      <th>NoSidewalk_max</th>\n",
       "      <th>Obstacle_max</th>\n",
       "      <th>Occlusion_max</th>\n",
       "      <th>Other_max</th>\n",
       "      <th>SurfaceProblem_max</th>\n",
       "      <th>u_lat</th>\n",
       "      <th>u_lon</th>\n",
       "      <th>v_lat</th>\n",
       "      <th>v_lon</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>317.313855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.662018</td>\n",
       "      <td>-122.322863</td>\n",
       "      <td>47.664871</td>\n",
       "      <td>-122.322864</td>\n",
       "      <td>0.778704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.772566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.648425</td>\n",
       "      <td>-122.342633</td>\n",
       "      <td>47.648600</td>\n",
       "      <td>-122.342604</td>\n",
       "      <td>0.802657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.534974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646925</td>\n",
       "      <td>-122.336374</td>\n",
       "      <td>47.646803</td>\n",
       "      <td>-122.336373</td>\n",
       "      <td>0.811780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.156787</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646921</td>\n",
       "      <td>-122.334031</td>\n",
       "      <td>47.647067</td>\n",
       "      <td>-122.334030</td>\n",
       "      <td>0.838597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.729261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.665809</td>\n",
       "      <td>-122.301937</td>\n",
       "      <td>47.665880</td>\n",
       "      <td>-122.302052</td>\n",
       "      <td>0.812195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  key  severityavg_severity  severitymax_severity  \\\n",
       "0           0  0.0                   1.0                   1.0   \n",
       "1           1  0.0                   1.0                   1.0   \n",
       "2           2  0.0                   2.0                   3.0   \n",
       "3           3  0.0                   1.0                   1.0   \n",
       "4           4  0.0                   3.0                   3.0   \n",
       "\n",
       "   severitynum_barriers  lengthfirst  CurbRamp_count  NoCurbRamp_count  \\\n",
       "0                     1   317.313855               1                 0   \n",
       "1                     2    19.772566               2                 0   \n",
       "2                     2    13.534974               2                 0   \n",
       "3                     2    16.156787               2                 0   \n",
       "4                     1    11.729261               1                 0   \n",
       "\n",
       "   NoSidewalk_count  Obstacle_count  ...  NoSidewalk_max  Obstacle_max  \\\n",
       "0                 0               0  ...             0.0           0.0   \n",
       "1                 0               0  ...             0.0           0.0   \n",
       "2                 0               0  ...             0.0           0.0   \n",
       "3                 0               0  ...             0.0           0.0   \n",
       "4                 0               0  ...             0.0           0.0   \n",
       "\n",
       "   Occlusion_max  Other_max  SurfaceProblem_max      u_lat       u_lon  \\\n",
       "0            0.0        0.0                 0.0  47.662018 -122.322863   \n",
       "1            0.0        0.0                 0.0  47.648425 -122.342633   \n",
       "2            0.0        0.0                 0.0  47.646925 -122.336374   \n",
       "3            0.0        0.0                 0.0  47.646921 -122.334031   \n",
       "4            0.0        0.0                 0.0  47.665809 -122.301937   \n",
       "\n",
       "       v_lat       v_lon      pred  \n",
       "0  47.664871 -122.322864  0.778704  \n",
       "1  47.648600 -122.342604  0.802657  \n",
       "2  47.646803 -122.336373  0.811780  \n",
       "3  47.647067 -122.334030  0.838597  \n",
       "4  47.665880 -122.302052  0.812195  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "466bd01a-a227-4358-97ea-dcb7168d94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mobility_issue_assistance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64287e0-1e5e-4344-b999-e42a4516a547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6baa714-8d35-482f-8b36-aa2e0bddda8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3da70603-8e83-4bd7-ae5b-0162f9687df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blind assitance GNN score - edge based v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "639e86bb-004b-45f5-a015-2ee2e29f4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Total Loss 9.8002\n",
      "Epoch 50 | Total Loss 0.0504\n",
      "Epoch 100 | Total Loss 0.0129\n",
      "Epoch 150 | Total Loss 0.0076\n",
      "Epoch 200 | Total Loss 0.0052\n",
      "\n",
      "Sync Complete. Top Blind Hazards:\n",
      "           u_lat       u_lon  Obstacle_count  pred_blind\n",
      "795    47.557401 -122.332420               0   10.000000\n",
      "791    47.559834 -122.332438               0   10.000000\n",
      "147    47.694085 -122.400649               0    9.851728\n",
      "39170  47.690536 -122.399722               0    9.851728\n",
      "1231   47.560286 -122.336764               0    9.740533\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP GRAPH & DATA\n",
    "G_full = ox.graph_from_place(\"Seattle, Washington, USA\", network_type=\"walk\")\n",
    "G_full = nx.Graph(G_full)\n",
    "df = x.copy()\n",
    "\n",
    "def key(lat, lon):\n",
    "    return (round(float(lat), 6), round(float(lon), 6))\n",
    "\n",
    "# Map coordinates to rows\n",
    "edge_features = {}\n",
    "for _, r in df.iterrows():\n",
    "    u, v = key(r.u_lat, r.u_lon), key(r.v_lat, r.v_lon)\n",
    "    edge_features[(u, v)] = edge_features[(v, u)] = r \n",
    "\n",
    "# Attach features to NetworkX\n",
    "for u, v in G_full.edges():\n",
    "    u_c = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_c = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    data_row = edge_features.get((u_c, v_c))\n",
    "    \n",
    "    # Default values\n",
    "    feats = {\"NoCurbRamp\": 0.0, \"NoSidewalk\": 0.0, \"Obstacle\": 0.0, \"CurbRamp\": 1.0, \"SurfaceProblem\": 0.0, \"Occlusion\": 0.0}\n",
    "    if data_row is not None:\n",
    "        feats = {k: float(data_row[f\"{k}_count\"]) for k in feats.keys()}\n",
    "    G_full[u][v][\"features\"] = feats\n",
    "\n",
    "# 2. DEFINE RISK FORMULAS\n",
    "def mobility_risk(f):\n",
    "    return (5.0 * f[\"NoCurbRamp\"] + 4.0 * f[\"NoSidewalk\"] + 3.0 * f[\"Obstacle\"] +\n",
    "            2.0 * max(0.0, 1.0 - f[\"CurbRamp\"]) + 1.5 * f[\"SurfaceProblem\"] + 1.0 * f[\"Occlusion\"])\n",
    "\n",
    "def blind_risk(f):\n",
    "    # Priority: Obstacle > Occlusion > No Sidewalk > Surface Prob > No Curb Ramp > Curb Ramp\n",
    "    return (6.0 * f[\"Obstacle\"] + 5.0 * f[\"Occlusion\"] + 4.0 * f[\"NoSidewalk\"] + \n",
    "            3.0 * f[\"SurfaceProblem\"] + 1.5 * f[\"NoCurbRamp\"] + 0.5 * max(0.0, 1.0 - f[\"CurbRamp\"]))\n",
    "\n",
    "# 3. PREPARE GNN DATA\n",
    "edge_list_coords = []\n",
    "x_feats, y_mobility, y_blind = [], [], []\n",
    "\n",
    "for u, v in G_full.edges():\n",
    "    u_c = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_c = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    canon = (u_c, v_c) if u_c <= v_c else (v_c, u_c)\n",
    "    edge_list_coords.append(canon)\n",
    "    \n",
    "    f = G_full[u][v][\"features\"]\n",
    "    x_feats.append([f[\"NoCurbRamp\"], f[\"NoSidewalk\"], f[\"Obstacle\"], f[\"CurbRamp\"], f[\"SurfaceProblem\"], f[\"Occlusion\"]])\n",
    "    y_mobility.append(mobility_risk(f))\n",
    "    y_blind.append(blind_risk(f))\n",
    "\n",
    "x_tensor = torch.tensor(x_feats, dtype=torch.float)\n",
    "y_tensor = torch.tensor([y_mobility, y_blind], dtype=torch.float).t() # [num_edges, 2]\n",
    "\n",
    "# Line Graph Indexing\n",
    "e2idx = {e: i for i, e in enumerate(edge_list_coords)}\n",
    "edge_index_list = []\n",
    "for w in G_full.nodes():\n",
    "    incident = [(key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]), key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])) \n",
    "                for u, v in G_full.edges(w)]\n",
    "    for i in range(len(incident)):\n",
    "        for j in range(i + 1, len(incident)):\n",
    "            u_i, v_i = incident[i]; canon_i = (u_i, v_i) if u_i <= v_i else (v_i, u_i)\n",
    "            u_j, v_j = incident[j]; canon_j = (u_j, v_j) if u_j <= v_j else (v_j, u_j)\n",
    "            ei, ej = e2idx[canon_i], e2idx[canon_j]\n",
    "            edge_index_list.extend([[ei, ej], [ej, ei]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# 4. MULTI-TARGET GNN MODEL\n",
    "class MultiAssistGNN(nn.Module):\n",
    "    def __init__(self, in_channels=6, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        self.gnn = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=2)\n",
    "        self.head = nn.Linear(hidden_channels, 2) # Output 2 values: [Mobility, Blind]\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.head(self.gnn(x, edge_index))\n",
    "\n",
    "model = MultiAssistGNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(201):\n",
    "    model.train(); opt.zero_grad()\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = ((pred - data.y) ** 2).mean()\n",
    "    loss.backward(); opt.step()\n",
    "    if epoch % 50 == 0: print(f\"Epoch {epoch} | Total Loss {loss.item():.4f}\")\n",
    "\n",
    "# 5. RESCALE & SYNC\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    raw_preds = model(data.x, data.edge_index).cpu().numpy()\n",
    "\n",
    "def get_normalized(arr):\n",
    "    p98 = np.percentile(arr, 98)\n",
    "    mn, mx = arr.min(), arr.max()\n",
    "    res = []\n",
    "    for v in arr:\n",
    "        if v <= p98: norm = 7.0 * (v - mn) / (p98 - mn) if p98 > mn else 0.0\n",
    "        else: norm = 7.0 + 3.0 * (v - p98) / (mx - p98) if mx > p98 else 10.0\n",
    "        res.append(norm)\n",
    "    return np.clip(res, 0, 10)\n",
    "\n",
    "norm_mobility = get_normalized(raw_preds[:, 0])\n",
    "norm_blind = get_normalized(raw_preds[:, 1])\n",
    "\n",
    "# Lookups\n",
    "mobility_map = {edge_list_coords[i]: norm_mobility[i] for i in range(len(edge_list_coords))}\n",
    "blind_map = {edge_list_coords[i]: norm_blind[i] for i in range(len(edge_list_coords))}\n",
    "\n",
    "def sync_row(row, risk_map):\n",
    "    u, v = key(row['u_lat'], row['u_lon']), key(row['v_lat'], row['v_lon'])\n",
    "    return risk_map.get((u, v) if u <= v else (v, u), 0.0)\n",
    "\n",
    "df['pred_mobility'] = df.apply(lambda r: sync_row(r, mobility_map), axis=1)\n",
    "df['pred_blind'] = df.apply(lambda r: sync_row(r, blind_map), axis=1)\n",
    "\n",
    "print(\"\\nSync Complete. Top Blind Hazards:\")\n",
    "print(df[['u_lat', 'u_lon', 'Obstacle_count', 'pred_blind']].sort_values(by='pred_blind', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c14ad7da-be04-4a83-a5f3-30cbca01c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>severityavg_severity</th>\n",
       "      <th>severitymax_severity</th>\n",
       "      <th>severitynum_barriers</th>\n",
       "      <th>lengthfirst</th>\n",
       "      <th>CurbRamp_count</th>\n",
       "      <th>NoCurbRamp_count</th>\n",
       "      <th>NoSidewalk_count</th>\n",
       "      <th>Obstacle_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Obstacle_max</th>\n",
       "      <th>Occlusion_max</th>\n",
       "      <th>Other_max</th>\n",
       "      <th>SurfaceProblem_max</th>\n",
       "      <th>u_lat</th>\n",
       "      <th>u_lon</th>\n",
       "      <th>v_lat</th>\n",
       "      <th>v_lon</th>\n",
       "      <th>pred_mobility</th>\n",
       "      <th>pred_blind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>317.313855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.662018</td>\n",
       "      <td>-122.322863</td>\n",
       "      <td>47.664871</td>\n",
       "      <td>-122.322864</td>\n",
       "      <td>0.918588</td>\n",
       "      <td>0.416122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.772566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.648425</td>\n",
       "      <td>-122.342633</td>\n",
       "      <td>47.648600</td>\n",
       "      <td>-122.342604</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.453777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.534974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646925</td>\n",
       "      <td>-122.336374</td>\n",
       "      <td>47.646803</td>\n",
       "      <td>-122.336373</td>\n",
       "      <td>0.912668</td>\n",
       "      <td>0.477343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.156787</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.646921</td>\n",
       "      <td>-122.334031</td>\n",
       "      <td>47.647067</td>\n",
       "      <td>-122.334030</td>\n",
       "      <td>0.905843</td>\n",
       "      <td>0.483761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.729261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.665809</td>\n",
       "      <td>-122.301937</td>\n",
       "      <td>47.665880</td>\n",
       "      <td>-122.302052</td>\n",
       "      <td>0.923740</td>\n",
       "      <td>0.453254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  key  severityavg_severity  severitymax_severity  \\\n",
       "0           0  0.0                   1.0                   1.0   \n",
       "1           1  0.0                   1.0                   1.0   \n",
       "2           2  0.0                   2.0                   3.0   \n",
       "3           3  0.0                   1.0                   1.0   \n",
       "4           4  0.0                   3.0                   3.0   \n",
       "\n",
       "   severitynum_barriers  lengthfirst  CurbRamp_count  NoCurbRamp_count  \\\n",
       "0                     1   317.313855               1                 0   \n",
       "1                     2    19.772566               2                 0   \n",
       "2                     2    13.534974               2                 0   \n",
       "3                     2    16.156787               2                 0   \n",
       "4                     1    11.729261               1                 0   \n",
       "\n",
       "   NoSidewalk_count  Obstacle_count  ...  Obstacle_max  Occlusion_max  \\\n",
       "0                 0               0  ...           0.0            0.0   \n",
       "1                 0               0  ...           0.0            0.0   \n",
       "2                 0               0  ...           0.0            0.0   \n",
       "3                 0               0  ...           0.0            0.0   \n",
       "4                 0               0  ...           0.0            0.0   \n",
       "\n",
       "   Other_max  SurfaceProblem_max      u_lat       u_lon      v_lat  \\\n",
       "0        0.0                 0.0  47.662018 -122.322863  47.664871   \n",
       "1        0.0                 0.0  47.648425 -122.342633  47.648600   \n",
       "2        0.0                 0.0  47.646925 -122.336374  47.646803   \n",
       "3        0.0                 0.0  47.646921 -122.334031  47.647067   \n",
       "4        0.0                 0.0  47.665809 -122.301937  47.665880   \n",
       "\n",
       "        v_lon  pred_mobility  pred_blind  \n",
       "0 -122.322864       0.918588    0.416122  \n",
       "1 -122.342604       0.889250    0.453777  \n",
       "2 -122.336373       0.912668    0.477343  \n",
       "3 -122.334030       0.905843    0.483761  \n",
       "4 -122.302052       0.923740    0.453254  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f92ba0-6744-48ed-a591-e37ddc850d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e68494-54bd-42a2-a36a-65e184a32bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9692dffd-7a9e-4e6a-ae20-13ebc1f70a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"blind_assitance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "945cf3c3-0eb2-4b64-8adb-3637fb9c2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal user GNN score - edge based v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e6fa1d30-9c15-47e1-8f6e-e0995330d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss 16.4712\n",
      "Epoch 50 | Loss 0.0937\n",
      "Epoch 100 | Loss 0.0211\n",
      "Epoch 150 | Loss 0.0100\n",
      "Epoch 200 | Loss 0.0060\n",
      "\n",
      "Sync Complete. Top Normal User Hazards (Priority: No Sidewalk/Obstacle):\n",
      "           u_lat       u_lon  NoSidewalk_count  Obstacle_count  pred_normal\n",
      "795    47.557401 -122.332420                27               0    10.000000\n",
      "791    47.559834 -122.332438                21               0    10.000000\n",
      "39170  47.690536 -122.399722                26               0     9.872221\n",
      "147    47.694085 -122.400649                29               0     9.872221\n",
      "1231   47.560286 -122.336764                22               0     9.758347\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP GRAPH & DATA\n",
    "G_full = ox.graph_from_place(\"Seattle, Washington, USA\", network_type=\"walk\")\n",
    "G_full = nx.Graph(G_full)\n",
    "df = x.copy()\n",
    "\n",
    "def key(lat, lon):\n",
    "    return (round(float(lat), 6), round(float(lon), 6))\n",
    "\n",
    "# Map coordinates to rows\n",
    "edge_features = {}\n",
    "for _, r in df.iterrows():\n",
    "    u, v = key(r.u_lat, r.u_lon), key(r.v_lat, r.v_lon)\n",
    "    edge_features[(u, v)] = edge_features[(v, u)] = r \n",
    "\n",
    "# Attach features to NetworkX\n",
    "for u, v in G_full.edges():\n",
    "    u_c = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_c = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    data_row = edge_features.get((u_c, v_c))\n",
    "    \n",
    "    feats = {\"NoCurbRamp\": 0.0, \"NoSidewalk\": 0.0, \"Obstacle\": 0.0, \"CurbRamp\": 1.0, \"SurfaceProblem\": 0.0, \"Occlusion\": 0.0}\n",
    "    if data_row is not None:\n",
    "        feats = {k: float(data_row[f\"{k}_count\"]) for k in feats.keys()}\n",
    "    G_full[u][v][\"features\"] = feats\n",
    "\n",
    "# 2. DEFINE RISK FORMULA FOR NORMAL USER\n",
    "def normal_risk(f):\n",
    "    # Priority: No Sidewalk > Obstacle > Surface Prob > Occlusion > CurbRamp > No CurbRamp\n",
    "    return (\n",
    "        6.0 * f[\"NoSidewalk\"] + \n",
    "        5.0 * f[\"Obstacle\"] + \n",
    "        4.0 * f[\"SurfaceProblem\"] + \n",
    "        3.0 * f[\"Occlusion\"] + \n",
    "        1.5 * f[\"CurbRamp\"] + \n",
    "        0.5 * f[\"NoCurbRamp\"]\n",
    "    )\n",
    "\n",
    "# 3. PREPARE GNN DATA\n",
    "edge_list_coords = []\n",
    "x_feats, y_normal = [], []\n",
    "\n",
    "for u, v in G_full.edges():\n",
    "    u_c = key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"])\n",
    "    v_c = key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])\n",
    "    canon = (u_c, v_c) if u_c <= v_c else (v_c, u_c)\n",
    "    edge_list_coords.append(canon)\n",
    "    \n",
    "    f = G_full[u][v][\"features\"]\n",
    "    x_feats.append([f[\"NoCurbRamp\"], f[\"NoSidewalk\"], f[\"Obstacle\"], f[\"CurbRamp\"], f[\"SurfaceProblem\"], f[\"Occlusion\"]])\n",
    "    y_normal.append(normal_risk(f))\n",
    "\n",
    "x_tensor = torch.tensor(x_feats, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_normal, dtype=torch.float) \n",
    "\n",
    "# Line Graph Indexing\n",
    "e2idx = {e: i for i, e in enumerate(edge_list_coords)}\n",
    "edge_index_list = []\n",
    "for w in G_full.nodes():\n",
    "    incident = [(key(G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]), key(G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"])) \n",
    "                for u, v in G_full.edges(w)]\n",
    "    for i in range(len(incident)):\n",
    "        for j in range(i + 1, len(incident)):\n",
    "            u_i, v_i = incident[i]; canon_i = (u_i, v_i) if u_i <= v_i else (v_i, u_i)\n",
    "            u_j, v_j = incident[j]; canon_j = (u_j, v_j) if u_j <= v_j else (v_j, u_j)\n",
    "            ei, ej = e2idx[canon_i], e2idx[canon_j]\n",
    "            edge_index_list.extend([[ei, ej], [ej, ei]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# 4. GNN MODEL\n",
    "class NormalAssistGNN(nn.Module):\n",
    "    def __init__(self, in_channels=6, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        self.gnn = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=2)\n",
    "        self.head = nn.Linear(hidden_channels, 1) \n",
    "    def forward(self, x, edge_index):\n",
    "        return self.head(self.gnn(x, edge_index)).squeeze(-1)\n",
    "\n",
    "model = NormalAssistGNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(201):\n",
    "    model.train(); opt.zero_grad()\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = ((pred - data.y) ** 2).mean()\n",
    "    loss.backward(); opt.step()\n",
    "    if epoch % 50 == 0: print(f\"Epoch {epoch} | Loss {loss.item():.4f}\")\n",
    "\n",
    "# 5. RESCALE & SYNC\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    raw_preds = model(data.x, data.edge_index).cpu().numpy()\n",
    "\n",
    "def get_normalized(arr):\n",
    "    p98 = np.percentile(arr, 98)\n",
    "    mn, mx = arr.min(), arr.max()\n",
    "    res = []\n",
    "    for v in arr:\n",
    "        if v <= p98: norm = 7.0 * (v - mn) / (p98 - mn) if p98 > mn else 0.0\n",
    "        else: norm = 7.0 + 3.0 * (v - p98) / (mx - p98) if mx > p98 else 10.0\n",
    "        res.append(norm)\n",
    "    return np.clip(res, 0, 10)\n",
    "\n",
    "norm_normal = get_normalized(raw_preds)\n",
    "normal_map = {edge_list_coords[i]: norm_normal[i] for i in range(len(edge_list_coords))}\n",
    "\n",
    "def sync_row(row, risk_map):\n",
    "    u, v = key(row['u_lat'], row['u_lon']), key(row['v_lat'], row['v_lon'])\n",
    "    return risk_map.get((u, v) if u <= v else (v, u), 0.0)\n",
    "\n",
    "df['pred_normal'] = df.apply(lambda r: sync_row(r, normal_map), axis=1)\n",
    "\n",
    "print(\"\\nSync Complete. Top Normal User Hazards (Priority: No Sidewalk/Obstacle):\")\n",
    "print(df[['u_lat', 'u_lon', 'NoSidewalk_count', 'Obstacle_count', 'pred_normal']].sort_values(by='pred_normal', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "419c9087-3574-41d6-a507-1b8e961eb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"normal_user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "31a68713-974c-4f3a-ada3-81f87523950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2076906d-4cbd-4bbc-aa98-6c798eae356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with Validation Split...\n",
      "Epoch   0 | Train Loss: 16.4363 | Test Loss: 14.4378\n",
      "Epoch  50 | Train Loss: 0.0794 | Test Loss: 0.0788\n",
      "Epoch 100 | Train Loss: 0.0118 | Test Loss: 0.0121\n",
      "Epoch 150 | Train Loss: 0.0050 | Test Loss: 0.0051\n",
      "Epoch 200 | Train Loss: 0.0030 | Test Loss: 0.0031\n",
      "\n",
      "--- Model Performance Metrics ---\n",
      "Mean Absolute Error (MAE): 0.0208\n",
      "Root Mean Squared Error (RMSE): 0.0553\n",
      "R-Squared (Variance Explained): 0.9997\n",
      "95% Confidence Margin of Error: ±0.1083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- (Previous Setup and Training Code remains same until Section 4) ---\n",
    "\n",
    "# 4. SPLIT DATA FOR VALIDATION\n",
    "# We create a mask to separate edges into training and testing sets\n",
    "num_nodes = data.num_nodes\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "model = NormalAssistGNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Starting Training with Validation Split...\")\n",
    "for epoch in range(201):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    \n",
    "    # Train only on the training subset\n",
    "    loss = ((pred[train_idx] - data.y[train_idx]) ** 2).mean()\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = ((pred[test_idx] - data.y[test_idx]) ** 2).mean()\n",
    "        print(f\"Epoch {epoch:3d} | Train Loss: {loss.item():.4f} | Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "# 5. CALCULATE ACCURACY & MARGIN OF ERROR\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_preds = model(data.x, data.edge_index).cpu().numpy()\n",
    "    y_true = data.y.cpu().numpy()\n",
    "\n",
    "# Calculate metrics on the test set (the data the model didn't train on)\n",
    "mae = mean_absolute_error(y_true[test_idx], all_preds[test_idx])\n",
    "rmse = np.sqrt(mean_squared_error(y_true[test_idx], all_preds[test_idx]))\n",
    "r2 = r2_score(y_true[test_idx], all_preds[test_idx])\n",
    "\n",
    "# Calculating \"Margin of Error\" at 95% confidence\n",
    "errors = all_preds[test_idx] - y_true[test_idx]\n",
    "margin_of_error = 1.96 * np.std(errors) \n",
    "\n",
    "print(\"\\n--- Model Performance Metrics ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\") \n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R-Squared (Variance Explained): {r2:.4f}\")\n",
    "print(f\"95% Confidence Margin of Error: ±{margin_of_error:.4f}\")\n",
    "\n",
    "# --- (Proceed to Section 6: Rescale & Sync as before) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e4635101-7500-4e94-a03c-634f4b990ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713245f-8818-4e53-8891-2cc2b2b59bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "# Center of Seattle walk network (OSMnx format)\n",
    "lats = [G_full.nodes[n][\"y\"] for n in G_full.nodes()]\n",
    "lons = [G_full.nodes[n][\"x\"] for n in G_full.nodes()]\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[np.mean(lats), np.mean(lons)],\n",
    "    zoom_start=13,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# Draw each edge, color-coded by normalized risk (TOP 5% red)\n",
    "for u, v, data in G_full.edges(data=True):\n",
    "    # Get node coordinates (OSMnx uses \"y\"=lat, \"x\"=lon)\n",
    "    lat_u, lon_u = G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]\n",
    "    lat_v, lon_v = G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"]\n",
    "    \n",
    "    # Get normalized risk (0-10 scale)\n",
    "    risk_norm = data.get(\"risk_norm\", 0.0)\n",
    "    \n",
    "    # Color: RED if >=7 (TOP 5% riskiest), GREEN if <7\n",
    "    color = \"red\" if risk_norm >= 7 else \"green\"\n",
    "    \n",
    "    # Tooltip with risk details\n",
    "    tooltip = f\"Risk: {risk_norm:.1f}/10\"\n",
    "    if \"wheelchair_cost\" in data:\n",
    "        tooltip += f\" | Cost: {data['wheelchair_cost']:.1f}\"\n",
    "    \n",
    "    folium.PolyLine(\n",
    "        locations=[[lat_u, lon_u], [lat_v, lon_v]],\n",
    "        color=color,\n",
    "        weight=4 if risk_norm >= 7 else 2,  # EXTRA thick for top 5%\n",
    "        opacity=0.9 if risk_norm >= 7 else 0.7,  # More opaque for high risk\n",
    "        tooltip=tooltip\n",
    "    ).add_to(m)\n",
    "\n",
    "# Updated legend for TOP 5%\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 220px; height: 90px; \n",
    "     background-color: white; border:2px solid grey; z-index:9999; \n",
    "     font-size:14px; padding: 10px; font-weight: bold;\">\n",
    "<p><span style=\"color: green;\">🟢 Green</span>: Safe (95% edges)</p>\n",
    "<p><span style=\"color: red;\">🔴 Red</span>: DANGER (TOP 5%)</p>\n",
    "<p><b>Only 5% edges are high risk</b></p>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "print(f\"Map created: {np.mean(risk_normalized >= 7)*100:.1f}% edges >= 7 (RED = TOP 5%)\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a5366-7a2b-4365-afd9-e4c2dd4b2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your existing map code, ADD THIS:\n",
    "\n",
    "# Example route coordinates\n",
    "route_coords = {\"start\": [47.6144219, -122.192337], \"end\": [45.6554303, -120.30016925]}\n",
    "\n",
    "# 1. Find nearest nodes and compute A* route\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "def euclidean_distance(u, v):\n",
    "    y1, x1 = G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]\n",
    "    y2, x2 = G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"]\n",
    "    return math.sqrt((y1 - y2)**2 + (x1 - x2)**2)\n",
    "\n",
    "# Get nearest nodes\n",
    "start_lat, start_lon = route_coords[\"start\"]\n",
    "end_lat, end_lon = route_coords[\"end\"]\n",
    "orig_node = ox.distance.nearest_nodes(G_full, X=start_lon, Y=start_lat)\n",
    "dest_node = ox.distance.nearest_nodes(G_full, X=end_lon, Y=end_lat)\n",
    "\n",
    "# A* using wheelchair_cost (AVOIDS red edges automatically)\n",
    "path_nodes = nx.astar_path(\n",
    "    G_full,\n",
    "    source=orig_node,\n",
    "    target=dest_node,\n",
    "    heuristic=lambda u, v: euclidean_distance(u, v),\n",
    "    weight=\"wheelchair_cost\"\n",
    ")\n",
    "\n",
    "# 2. Extract route metrics\n",
    "route_edges = list(zip(path_nodes[:-1], path_nodes[1:]))\n",
    "route_risks = []\n",
    "route_lengths = []\n",
    "total_length = 0\n",
    "high_risk_count = 0\n",
    "\n",
    "for u, v in route_edges:\n",
    "    edge_data = G_full[u][v]\n",
    "    risk_norm = edge_data.get(\"risk_norm\", 0.0)\n",
    "    length = edge_data.get(\"length\", 0.0)\n",
    "    \n",
    "    route_risks.append(risk_norm)\n",
    "    route_lengths.append(length)\n",
    "    total_length += length\n",
    "    if risk_norm >= 7:\n",
    "        high_risk_count += 1\n",
    "\n",
    "avg_risk = np.mean(route_risks)\n",
    "num_edges = len(route_edges)\n",
    "\n",
    "# 3. PLOT SAFEST ROUTE (thick BLUE line)\n",
    "route_coords_map = [[G_full.nodes[n][\"y\"], G_full.nodes[n][\"x\"]] for n in path_nodes]\n",
    "folium.PolyLine(\n",
    "    locations=route_coords_map,\n",
    "    color=\"blue\",\n",
    "    weight=8,\n",
    "    opacity=0.95,\n",
    "    tooltip=f\"🛡️ SAFEST ROUTE (Avg Risk: {avg_risk:.1f}/10)\"\n",
    ").add_to(m)\n",
    "\n",
    "# 4. Start/End markers\n",
    "folium.Marker(\n",
    "    [start_lat, start_lon], popup=\"🚩 START\",\n",
    "    icon=folium.Icon(color=\"green\", icon=\"play\")\n",
    ").add_to(m)\n",
    "folium.Marker(\n",
    "    [end_lat, end_lon], popup=\"🏁 END\",\n",
    "    icon=folium.Icon(color=\"red\", icon=\"stop\")\n",
    ").add_to(m)\n",
    "\n",
    "# 5. Updated legend WITH ROUTE METRICS\n",
    "legend_html = f'''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 280px; height: 160px; \n",
    "     background-color: white; border:2px solid grey; z-index:9999; \n",
    "     font-size:14px; padding: 15px; font-weight: bold;\">\n",
    "<p><span style=\"color: green;\">🟢 Green:</span> Safe (95% edges)</p>\n",
    "<p><span style=\"color: red;\">🔴 Red:</span> DANGER (TOP 5%)</p>\n",
    "<p><span style=\"color: blue; font-weight: bold;\">🔵 Blue:</span> YOUR SAFEST ROUTE</p>\n",
    "<hr>\n",
    "<p><b>📊 ROUTE METRICS:</b></p>\n",
    "<p>Avg Risk: <span style=\"color:blue\">{avg_risk:.1f}/10</span></p>\n",
    "<p>Length: <span style=\"color:green\">{total_length:.0f}m</span></p>\n",
    "<p>High Risk Edges: <span style=\"color:orange\">{high_risk_count}</span></p>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# 6. Print metrics summary\n",
    "print(f\"\\n🛤️ ROUTE COMPLETE!\")\n",
    "print(f\"Avg Risk Score:     {avg_risk:.2f}/10\")\n",
    "print(f\"Total Length:       {total_length:.0f} meters\") \n",
    "print(f\"Number of Edges:    {num_edges}\")\n",
    "print(f\"High Risk Edges:    {high_risk_count} (should be 0!)\")\n",
    "print(f\"Safety Score:       {100*(1 - high_risk_count/num_edges):.1f}% safe\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d105c3-54c2-4fee-be14-f3b0381d4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE your existing route code with this DUAL ROUTE version:\n",
    "\n",
    "# Example route coordinates\n",
    "route_coords = {\"start\": [47.6144219, -122.192337], \"end\": [45.6554303, -120.30016925]}\n",
    "\n",
    "# 1. Helper functions\n",
    "def euclidean_distance(u, v):\n",
    "    y1, x1 = G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]\n",
    "    y2, x2 = G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"]\n",
    "    return math.sqrt((y1 - y2)**2 + (x1 - x2)**2)\n",
    "\n",
    "def compute_route_metrics(path_nodes):\n",
    "    \"\"\"Extract metrics for any route\"\"\"\n",
    "    route_edges = list(zip(path_nodes[:-1], path_nodes[1:]))\n",
    "    route_risks = []\n",
    "    route_lengths = []\n",
    "    total_length = 0\n",
    "    high_risk_count = 0\n",
    "    \n",
    "    for u, v in route_edges:\n",
    "        edge_data = G_full[u][v]\n",
    "        risk_norm = edge_data.get(\"risk_norm\", 0.0)\n",
    "        length = edge_data.get(\"length\", 0.0)\n",
    "        wheelchair_cost = edge_data.get(\"wheelchair_cost\", 0.0)\n",
    "        \n",
    "        route_risks.append(risk_norm)\n",
    "        route_lengths.append(length)\n",
    "        total_length += length\n",
    "        if risk_norm >= 7:\n",
    "            high_risk_count += 1\n",
    "    \n",
    "    return {\n",
    "        'path_nodes': path_nodes,\n",
    "        'avg_risk': np.mean(route_risks),\n",
    "        'total_length': total_length,\n",
    "        'num_edges': len(route_edges),\n",
    "        'high_risk_count': high_risk_count,\n",
    "        'total_cost': sum(G_full[u][v][\"wheelchair_cost\"] for u, v in route_edges),\n",
    "        'route_coords': [[G_full.nodes[n][\"y\"], G_full.nodes[n][\"x\"]] for n in path_nodes]\n",
    "    }\n",
    "\n",
    "# 2. ROUTE 1: Length-only (orange - ignores risk)\n",
    "start_lat, start_lon = route_coords[\"start\"]\n",
    "end_lat, end_lon = route_coords[\"end\"]\n",
    "orig_node = ox.distance.nearest_nodes(G_full, X=start_lon, Y=start_lat)\n",
    "dest_node = ox.distance.nearest_nodes(G_full, X=end_lon, Y=end_lat)\n",
    "\n",
    "length_route = nx.astar_path(\n",
    "    G_full, orig_node, dest_node,\n",
    "    heuristic=lambda u, v: euclidean_distance(u, v),\n",
    "    weight=\"length\"\n",
    ")\n",
    "length_metrics = compute_route_metrics(length_route)\n",
    "\n",
    "# 3. ROUTE 2: Risk-aware wheelchair route (blue - avoids danger)\n",
    "risk_route = nx.astar_path(\n",
    "    G_full, orig_node, dest_node,\n",
    "    heuristic=lambda u, v: euclidean_distance(u, v),\n",
    "    weight=\"wheelchair_cost\"\n",
    ")\n",
    "risk_metrics = compute_route_metrics(risk_route)\n",
    "\n",
    "# 4. PLOT BOTH ROUTES ON SAME MAP\n",
    "# Length-only route (ORANGE - may go through red zones)\n",
    "# REPLACE your route plotting section with this ENHANCED version:\n",
    "\n",
    "# 4. PLOT BOTH ROUTES (with higher weight + layer ordering)\n",
    "# Length-only route (ORANGE - on TOP)\n",
    "folium.PolyLine(\n",
    "    locations=length_metrics['route_coords'],\n",
    "    color=\"orange\",\n",
    "    weight=10,      # THICKER\n",
    "    opacity=1.0,    # FULLY OPAQUE\n",
    "    dash_array='10', # DASHED to distinguish\n",
    "    tooltip=f\"📏 LENGTH-ONLY\\nAvg Risk: {length_metrics['avg_risk']:.1f}/10\\nLength: {length_metrics['total_length']:.0f}m\"\n",
    ").add_to(m)\n",
    "\n",
    "# Risk-aware route (BLUE - on TOP of orange) \n",
    "folium.PolyLine(\n",
    "    locations=risk_metrics['route_coords'],\n",
    "    color=\"darkblue\",  # DARKER blue\n",
    "    weight=12,         # THICKEST\n",
    "    opacity=1.0,       # FULLY OPAQUE\n",
    "    tooltip=f\"🛡️ RISK-AWARE (RECOMMENDED)\\nAvg Risk: {risk_metrics['avg_risk']:.1f}/10\\nLength: {risk_metrics['total_length']:.0f}m\"\n",
    ").add_to(m)\n",
    "\n",
    "# 5. Start/End markers (on TOP)\n",
    "folium.Marker(\n",
    "    [start_lat, start_lon], popup=\"🚩 START\", \n",
    "    icon=folium.Icon(color=\"green\", icon=\"play\", prefix=\"fa\", icon_size=(30,30))\n",
    ").add_to(m)\n",
    "folium.Marker(\n",
    "    [end_lat, end_lon], popup=\"🏁 END\", \n",
    "    icon=folium.Icon(color=\"red\", icon=\"flag\", prefix=\"fa\", icon_size=(30,30))\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "# 6. DUAL ROUTE COMPARISON LEGEND\n",
    "legend_html = f'''\n",
    "<div style=\"position: fixed; bottom: 20px; left: 20px; width: 320px; height: 220px; \n",
    "     background-color: white; border:3px solid #333; z-index:9999; font-size:13px; \n",
    "     padding: 15px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.3)\">\n",
    "<h4 style=\"margin-top:0; color:#1f77b4\">⚖️ ROUTE COMPARISON</h4>\n",
    "\n",
    "<p><span style=\"color:orange\">🟠 Length-only:</span><br>\n",
    "  <small>Avg Risk: <b>{length_metrics[\"avg_risk\"]:.1f}/10</b> | {length_metrics[\"total_length\"]:.0f}m | \n",
    "  Danger edges: {length_metrics[\"high_risk_count\"]}</small></p>\n",
    "\n",
    "<p><span style=\"color:blue; font-weight:bold\">🔵 Risk-aware:</span><br> \n",
    "  <small>Avg Risk: <b>{risk_metrics[\"avg_risk\"]:.1f}/10</b> | {risk_metrics[\"total_length\"]:.0f}m | \n",
    "  Danger edges: {risk_metrics[\"high_risk_count\"]}</small></p>\n",
    "\n",
    "<hr style=\"margin:10px 0\">\n",
    "<p><span style=\"color:green\">🟢 Green:</span> Safe (95%)</p>\n",
    "<p><span style=\"color:red\">🔴 Red:</span> DANGER (Top 5%)</p>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# 7. Print comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 ROUTE COMPARISON TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<20} {'Length-Only':<12} {'Risk-Aware':<12} {'Winner'}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Avg Risk Score     {length_metrics['avg_risk']:>10.2f}     {risk_metrics['avg_risk']:>10.2f}     {'🟢' if risk_metrics['avg_risk'] < length_metrics['avg_risk'] else '🔴'}\")\n",
    "print(f\"Total Length (m)   {length_metrics['total_length']:>10.0f}     {risk_metrics['total_length']:>10.0f}     {'🟢' if length_metrics['total_length'] < risk_metrics['total_length'] else '🔴'}\")\n",
    "print(f\"High Risk Edges    {length_metrics['high_risk_count']:>10}     {risk_metrics['high_risk_count']:>10}     {'🟢' if risk_metrics['high_risk_count'] < length_metrics['high_risk_count'] else '🔴'}\")\n",
    "print(f\"Total Cost         {length_metrics['total_cost']:>10.1f}     {risk_metrics['total_cost']:>10.1f}     {'🟢' if risk_metrics['total_cost'] < length_metrics['total_cost'] else '🔴'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8be63-0c41-46c3-8431-beb23d6a951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TWO SEPARATE MAPS - one for each route\n",
    "\n",
    "# 1. Map 1: LENGTH-ONLY ROUTE (orange)\n",
    "m1 = folium.Map(\n",
    "    location=[np.mean(lats), np.mean(lons)],\n",
    "    zoom_start=13,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# Background risk (same for both maps)\n",
    "for u, v, data in list(G_full.edges(data=True))[:10000]:  # Limit for speed\n",
    "    lat_u, lon_u = G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]\n",
    "    lat_v, lon_v = G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"]\n",
    "    risk_norm = data.get(\"risk_norm\", 0.0)\n",
    "    color = \"red\" if risk_norm >= 7 else \"lightgreen\"\n",
    "    \n",
    "    folium.PolyLine(\n",
    "        locations=[[lat_u, lon_u], [lat_v, lon_v]],\n",
    "        color=color,\n",
    "        weight=1.5 if risk_norm >= 7 else 1,\n",
    "        opacity=0.3\n",
    "    ).add_to(m1)\n",
    "\n",
    "# LENGTH-ONLY ROUTE (ORANGE - thick)\n",
    "folium.PolyLine(\n",
    "    locations=length_metrics['route_coords'],\n",
    "    color=\"orange\",\n",
    "    weight=10,\n",
    "    opacity=1.0,\n",
    "    tooltip=f\"📏 LENGTH ROUTE\\nRisk: {length_metrics['avg_risk']:.1f}/10\\n{length_metrics['total_length']:.0f}m\"\n",
    ").add_to(m1)\n",
    "\n",
    "# Start/End markers\n",
    "folium.Marker([start_lat, start_lon], popup=\"START\", \n",
    "              icon=folium.Icon(color=\"green\")).add_to(m1)\n",
    "folium.Marker([end_lat, end_lon], popup=\"END\", \n",
    "              icon=folium.Icon(color=\"red\")).add_to(m1)\n",
    "\n",
    "# Length route legend\n",
    "m1_legend = f'''\n",
    "<div style=\"position:fixed; bottom:20px; left:20px; width:250px; height:140px; \n",
    "     background:white; border:2px solid grey; z-index:9999; padding:10px\">\n",
    "<b>📏 LENGTH-ONLY ROUTE</b><br>\n",
    "Avg Risk: <span style=\"color:orange\">{length_metrics['avg_risk']:.1f}/10</span><br>\n",
    "Length: <span style=\"color:green\">{length_metrics['total_length']:.0f}m</span><br>\n",
    "Danger edges: {length_metrics['high_risk_count']}<br>\n",
    "🟢95% Safe | 🔴Top 5% Danger\n",
    "</div>\n",
    "'''\n",
    "m1.get_root().html.add_child(folium.Element(m1_legend))\n",
    "\n",
    "# 2. Map 2: RISK-AWARE ROUTE (blue)\n",
    "m2 = folium.Map(\n",
    "    location=[np.mean(lats), np.mean(lons)],\n",
    "    zoom_start=13,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# Same background risk\n",
    "for u, v, data in list(G_full.edges(data=True))[:10000]:\n",
    "    lat_u, lon_u = G_full.nodes[u][\"y\"], G_full.nodes[u][\"x\"]\n",
    "    lat_v, lon_v = G_full.nodes[v][\"y\"], G_full.nodes[v][\"x\"]\n",
    "    risk_norm = data.get(\"risk_norm\", 0.0)\n",
    "    color = \"red\" if risk_norm >= 7 else \"lightgreen\"\n",
    "    \n",
    "    folium.PolyLine(\n",
    "        locations=[[lat_u, lon_u], [lat_v, lon_v]],\n",
    "        color=color,\n",
    "        weight=1.5 if risk_norm >= 7 else 1,\n",
    "        opacity=0.3\n",
    "    ).add_to(m2)\n",
    "\n",
    "# RISK-AWARE ROUTE (BLUE - thickest)\n",
    "folium.PolyLine(\n",
    "    locations=risk_metrics['route_coords'],\n",
    "    color=\"darkblue\",\n",
    "    weight=12,\n",
    "    opacity=1.0,\n",
    "    tooltip=f\"🛡️ RISK ROUTE (RECOMMENDED)\\nRisk: {risk_metrics['avg_risk']:.1f}/10\\n{risk_metrics['total_length']:.0f}m\"\n",
    ").add_to(m2)\n",
    "\n",
    "# Start/End markers\n",
    "folium.Marker([start_lat, start_lon], popup=\"START\", \n",
    "              icon=folium.Icon(color=\"green\")).add_to(m2)\n",
    "folium.Marker([end_lat, end_lon], popup=\"END\", \n",
    "              icon=folium.Icon(color=\"red\")).add_to(m2)\n",
    "\n",
    "# Risk route legend\n",
    "m2_legend = f'''\n",
    "<div style=\"position:fixed; bottom:20px; left:20px; width:250px; height:140px; \n",
    "     background:white; border:2px solid grey; z-index:9999; padding:10px\">\n",
    "<b>🛡️ RISK-AWARE ROUTE</b><br>\n",
    "Avg Risk: <span style=\"color:blue\">{risk_metrics['avg_risk']:.1f}/10</span><br>\n",
    "Length: <span style=\"color:green\">{risk_metrics['total_length']:.0f}m</span><br>\n",
    "Danger edges: {risk_metrics['high_risk_count']}<br>\n",
    "🟢95% Safe | 🔴Top 5% Danger\n",
    "</div>\n",
    "'''\n",
    "m2.get_root().html.add_child(folium.Element(m2_legend))\n",
    "\n",
    "# 3. COMPARISON TABLE\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🔄 TWO ROUTES COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<18} {'LENGTH ROUTE':<15} {'RISK ROUTE':<15} {'DIFFERENCE'}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Avg Risk         {length_metrics['avg_risk']:>12.2f}     {risk_metrics['avg_risk']:>12.2f}     {risk_metrics['avg_risk']-length_metrics['avg_risk']:>+7.2f}\")\n",
    "print(f\"Total Length     {length_metrics['total_length']:>12.0f}m   {risk_metrics['total_length']:>12.0f}m   {risk_metrics['total_length']-length_metrics['total_length']:>+7.0f}m\")\n",
    "print(f\"Danger Edges     {length_metrics['high_risk_count']:>12}     {risk_metrics['high_risk_count']:>12}     {'🟢 BETTER' if risk_metrics['high_risk_count'] < length_metrics['high_risk_count'] else '🔴 WORSE'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Display both maps\n",
    "print(\"\\n🗺️ MAP 1: LENGTH-ONLY ROUTE (ORANGE)\")\n",
    "m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a53f9-f954-47c2-bcac-e7bc803963ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n🗺️ MAP 2: RISK-AWARE ROUTE (BLUE - RECOMMENDED)\")\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37bdd1-8ed9-4572-80fb-bc327d293561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
